{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f950321-79bb-4264-b2fd-9ef7595456a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T16:54:09.363845Z",
     "iopub.status.busy": "2025-02-27T16:54:09.363572Z",
     "iopub.status.idle": "2025-02-27T16:54:09.366100Z",
     "shell.execute_reply": "2025-02-27T16:54:09.365703Z",
     "shell.execute_reply.started": "2025-02-27T16:54:09.363830Z"
    }
   },
   "source": [
    "# Mass Map around Abell 360\n",
    "\n",
    "Anthony Englert\\\n",
    "LSST Science Piplines version: w_2025_43\\\n",
    "Container Size: 16GB\n",
    "\n",
    "This notebook is a first attempt at building a mass map of Abell 360 cluster from ComCam data, with the following main steps:\n",
    "\n",
    "- Loading the relevant object catalogs (all tracts and patches needed) using the butler\n",
    "- Color cut source selection\n",
    "- HSC lensing quality cuts\n",
    "- HSC calibration step. You will need to run the `gen_hsc_calibration` script outside of this notebook. The script is publicly available at: [https://github.com/PrincetonUniversity/hsc-y1-shear-calib](https://github.com/PrincetonUniversity/hsc-y1-shear-calib)\n",
    "- Computing mass map from calibrated shapes\n",
    "\n",
    "The first portion of this borrows from Celine's script to select galaxies redder than the red-sequence, then uses code developed for the Local Volume Complete Cluster Survey (Fu et al. 2022, 2024) to compute the mass map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34840e55-4119-4612-a769-a808b6e97d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general python packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.table import Table, vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583b109a-0868-43f6-8abc-36a915f69c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.daf.butler import Butler\n",
    "import lsst.geom as geom\n",
    "import lsst.afw.geom as afwGeom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d278a3-37a4-423a-8f9e-65eba7b9402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import to_rgba\n",
    "from matplotlib.patches import Patch\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "from matplotlib.lines import Line2D\n",
    "from astropy.table import Table, join, vstack\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord\n",
    "# %matplotlib widget\n",
    "import h5py\n",
    "import qp\n",
    "\n",
    "import healsparse as hsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38325d14-740b-43ec-9b3c-79d820890543",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"dp1\"\n",
    "collection = \"LSSTComCam/DP1\"\n",
    "#repo = '/repo/main'\n",
    "#collection = 'LSSTComCam/runs/DRP/DP1/w_2025_08/DM-49029'\n",
    "\n",
    "butler = Butler(repo, collections=collection)\n",
    "assert butler is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d19d115-4e0a-460d-a2eb-74dbf31fc5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "skymap = butler.get('skyMap', skymap='lsst_cells_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93de23f3-6156-4367-aa81-f024882dd2f3",
   "metadata": {},
   "source": [
    "## Find tracts and patches for Abell 360 and load the catalogs\n",
    "\n",
    "Find all the tracts/patches that falls in a given region around the A360 BCG, and store the results in a dictionary `tp_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68864e5c-d7b7-40db-b564-8e189894346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position of the BCG for A360\n",
    "ra_bcg, dec_bcg = (37.865016598, 6.9822048155)\n",
    "\n",
    "# Looking for all patches in delta deg region around it\n",
    "delta = 0.5\n",
    "center = geom.SpherePoint(ra_bcg, dec_bcg, geom.degrees)\n",
    "ra_min, ra_max = ra_bcg - delta, ra_bcg + delta\n",
    "dec_min, dec_max = dec_bcg - delta, dec_bcg + delta\n",
    "\n",
    "ra_range = (ra_min, ra_max)\n",
    "dec_range = (dec_min, dec_max)\n",
    "radec = [geom.SpherePoint(ra_range[0], dec_range[0], geom.degrees),\n",
    "         geom.SpherePoint(ra_range[0], dec_range[1], geom.degrees),\n",
    "         geom.SpherePoint(ra_range[1], dec_range[0], geom.degrees),\n",
    "         geom.SpherePoint(ra_range[1], dec_range[1], geom.degrees)]\n",
    "\n",
    "tracts_and_patches = skymap.findTractPatchList(radec)\n",
    "\n",
    "tp_dict = {}\n",
    "for tract_num in np.arange(len(tracts_and_patches)):\n",
    "    tract_info = tracts_and_patches[tract_num][0]\n",
    "    tract_idx = tract_info.getId()\n",
    "    # All the patches around the cluster\n",
    "    patches = []\n",
    "    for i,patch in enumerate(tracts_and_patches[tract_num][1]):\n",
    "        patch_info = tracts_and_patches[tract_num][1][i]\n",
    "        patch_idx = patch_info.sequential_index\n",
    "        patches.append(patch_idx)\n",
    "    tp_dict.update({tract_idx:patches})\n",
    "#tp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9523bf59-d30d-49fb-bb1c-02ace8a32992",
   "metadata": {},
   "source": [
    "Load the object catalogs for all these tracts/patches, make basic cuts, and store in a single merged catalog `merged_cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c347af7-c268-4ef4-b0db-e836fdbecc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Filtered patch {patch} in tract {tract}\")\n",
    "\n",
    "column_list = [\n",
    "                       'objectId','tract','patch','coord_ra','coord_dec',\n",
    "                       'r_cModel_flag','i_cModel_flag','refExtendedness','i_iPSF_flag',\n",
    "                       'i_cModelFlux','i_cModelFluxErr',\n",
    "                       'g_cModelFlux','g_cModelFluxErr',\n",
    "                       'r_cModelFlux','r_cModelFluxErr',\n",
    "                       'z_cModelFlux','z_cModelFluxErr',\n",
    "                       'i_ixxPSF','i_iyyPSF','i_ixyPSF','i_ixx','i_iyy','i_ixy',\n",
    "                       'i_hsmShapeRegauss_e1','i_hsmShapeRegauss_e2','i_hsmShapeRegauss_sigma',\n",
    "                       'i_hsmShapeRegauss_flag','i_blendedness',\n",
    "                      ]\n",
    "\n",
    "merged_cat = pd.DataFrame()\n",
    "\n",
    "for tract in tp_dict.keys():\n",
    "    print(f'Loading objects from tract {tract}, patches:{tp_dict[tract]}')\n",
    "    dataId = {'tract': tract ,'skymap':'lsst_cells_v1'}\n",
    "    obj_cat = butler.get('object', dataId=dataId, parameters={'columns': column_list})\n",
    "    obj_cat = obj_cat.to_pandas()\n",
    "    filt = obj_cat['r_cModel_flag']== False\n",
    "    filt &= obj_cat['i_cModel_flag']== False\n",
    "    filt &= obj_cat['r_cModelFlux']>0\n",
    "    filt &= obj_cat['i_cModelFlux']>0\n",
    "    filt &= obj_cat['refExtendedness'] > 0.5\n",
    "        \n",
    "    merged_cat = pd.concat([merged_cat, obj_cat[filt]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c636a87-b1b2-41c1-8bfa-f3b9de976d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "'objectId' in list(merged_cat.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74c09d4-b618-4746-af0c-324e325471a0",
   "metadata": {},
   "source": [
    "## Red sequence identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df7eeb-88b3-463c-ba8e-1eeff5a440a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:09:33.227567Z",
     "iopub.status.busy": "2025-03-11T08:09:33.226937Z",
     "iopub.status.idle": "2025-03-11T08:09:33.229610Z",
     "shell.execute_reply": "2025-03-11T08:09:33.229178Z",
     "shell.execute_reply.started": "2025-03-11T08:09:33.227548Z"
    }
   },
   "source": [
    "### Select a circular field close (<0.1 deg) to the BCG in order to identify RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae72749b-f31b-4e4c-8037-4754f63277fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "c1 = SkyCoord(merged_cat['coord_ra'].values*u.deg, merged_cat['coord_dec'].values*u.deg)\n",
    "c2 = SkyCoord(ra_bcg*u.deg, dec_bcg*u.deg)\n",
    "sep = c1.separation(c2)\n",
    "\n",
    "sep.deg\n",
    "filt = sep.deg < 0.1 # stay close to cluster center for RS indentification\n",
    "merged_cat_rs = merged_cat[filt] # catalog for RS identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704bddeb-a247-4164-bcdb-20850d761847",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_cat), len(merged_cat_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d04d17-6909-42d6-8528-c16016c3487d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T10:09:09.316496Z",
     "iopub.status.busy": "2024-12-10T10:09:09.316212Z",
     "iopub.status.idle": "2024-12-10T10:09:09.321215Z",
     "shell.execute_reply": "2024-12-10T10:09:09.318432Z",
     "shell.execute_reply.started": "2024-12-10T10:09:09.316483Z"
    }
   },
   "source": [
    "### Convert fluxes to magnitudes and identify red sequence in r-i versus r\n",
    "\n",
    "Conversion from fluxes to mag using formula from DP0.2 tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d210781e-d08f-489c-9876-81ca1aba6450",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_i = -2.50 * np.log10(merged_cat_rs['i_cModelFlux']) + 31.4\n",
    "mag_r = -2.50 * np.log10(merged_cat_rs['r_cModelFlux']) + 31.4\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8,4))\n",
    "ax[0].hist(mag_r, bins=50)\n",
    "ax[1].hist(mag_i, bins=50)\n",
    "ax[0].set_yscale('log')\n",
    "ax[1].set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eda95fc-5e57-4d06-84d5-9c01b2a6a17d",
   "metadata": {},
   "source": [
    "### Color magnitude diagram and by eye indetification of the red sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab9eff-f4ff-4aa5-89fb-014da9d5c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, \n",
    "                         figsize=(4,4))\n",
    "ax.scatter(mag_r, mag_r-mag_i, marker='.', s=0.3)\n",
    "ax.set_ylim([-2,2])\n",
    "ax.set_xlim([19,25])\n",
    "ax.set_ylabel('r-i')\n",
    "ax.set_xlabel('r')\n",
    "ax.plot([19,24],[0.4,0.3], color='r', linewidth=0.7)\n",
    "ax.plot([19,24],[0.6,0.5], color='r', linewidth=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88a4db6-9b71-4c44-8bd9-3dc775a0875c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:13:37.716333Z",
     "iopub.status.busy": "2025-03-11T08:13:37.715720Z",
     "iopub.status.idle": "2025-03-11T08:13:37.718367Z",
     "shell.execute_reply": "2025-03-11T08:13:37.717968Z",
     "shell.execute_reply.started": "2025-03-11T08:13:37.716316Z"
    }
   },
   "source": [
    "### Filter to identify red sequence galaxies in the sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5eeca9-03e8-484f-9aea-02b33ea1fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_hi = 0.6 - (0.1/5.) * (mag_r-19)\n",
    "rs_low = 0.4 - (0.1/5.)* (mag_r-19)\n",
    "color = mag_r - mag_i\n",
    "\n",
    "idx = np.where(np.logical_and(color>rs_low, color<rs_hi))[0]\n",
    "idx2 = np.where(mag_r.iloc[idx] < 23)[0] # keep the brightest objects only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638867fe-f9d1-4426-828c-d6b7132c918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, \n",
    "                         figsize=(4,4))\n",
    "ax.scatter(mag_r, mag_r-mag_i, marker='.', s=0.3) # all galaxies  \n",
    "ax.scatter(mag_r.iloc[idx].iloc[idx2], \n",
    "           mag_r.iloc[idx].iloc[idx2]-mag_i.iloc[idx].iloc[idx2], \n",
    "           marker='.', s=0.3) #red sequence galaxies\n",
    "ax.set_ylim([-2,2])\n",
    "ax.set_xlim([19,27])\n",
    "ax.set_ylabel('r-i')\n",
    "ax.set_xlabel('r')\n",
    "ax.plot([19,24],[0.4,0.3], color='r', linewidth=0.7)\n",
    "ax.plot([19,24],[0.6,0.5], color='r', linewidth=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154c23e9-caf3-42bd-ac24-374f6fbee153",
   "metadata": {},
   "source": [
    "## Remove red sequence galaxies in the full field\n",
    "\n",
    "For the analysis, we'll keep source galaxies within 0.5 deg from the BCG. Now we apply the RS cut defined on the small region above to the full field of the analysis. The RS-free catalog is stored as `merged_cat_wl`. The lensing quality cuts will be performed in a subsequent step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150c83a6-a33f-412a-a34a-3e54fe9721b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = sep.deg < 0.5 # larger field for analysis\n",
    "merged_cat_wl = merged_cat[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395f01c-04c5-4bbe-bdda-7bef379331ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_i = -2.50 * np.log10(merged_cat_wl['i_cModelFlux']) + 31.4\n",
    "mag_r = -2.50 * np.log10(merged_cat_wl['r_cModelFlux']) + 31.4\n",
    "color = mag_r - mag_i\n",
    "\n",
    "# Filter defined above applied to the full sample\n",
    "rs_hi = 0.6 - (0.1/5.) * (mag_r-19)\n",
    "rs_low = 0.4 - (0.1/5.)* (mag_r-19)\n",
    "\n",
    "idx = np.where(np.logical_and(color>rs_low, color<rs_hi))[0]\n",
    "idx2 = np.where(mag_r.iloc[idx] < 23)[0] # keep the brightest objects only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdc7359-5f3d-4498-aefb-5a00cf34c0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, \n",
    "                         figsize=(4,4))\n",
    "ax.scatter(mag_r, mag_r-mag_i, marker='.', s=0.3) # all galaxies  \n",
    "ax.scatter(mag_r.iloc[idx].iloc[idx2], \n",
    "           mag_r.iloc[idx].iloc[idx2]-mag_i.iloc[idx].iloc[idx2], \n",
    "           marker='.', s=0.3) #red sequence galaxies\n",
    "ax.set_ylim([-2,2])\n",
    "ax.set_xlim([19,27])\n",
    "ax.set_ylabel('r-i')\n",
    "ax.set_xlabel('r')\n",
    "ax.plot([19,24],[0.4,0.3], color='r', linewidth=0.7)\n",
    "ax.plot([19,24],[0.6,0.5], color='r', linewidth=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56544c-49a5-4f5f-a61e-ed8d1caf02eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RS_id_list = merged_cat_wl['objectId'].iloc[idx].iloc[idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e3236a-398e-47d5-9e7d-1e4bc4e38b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(RS_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33932b2e-f50f-4584-9247-758ab488d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where the 'dataid' column matches any value in RS_id_list\n",
    "merged_cat_wl = merged_cat_wl[~merged_cat_wl['objectId'].isin(RS_id_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538590f5-86e8-408d-8086-907d16dbeba4",
   "metadata": {},
   "source": [
    "## Lensing cuts\n",
    "\n",
    "The RS sequence has been removed. Now apply a series of lensing cuts (mostly following Shenming's [CLMM HSC demo analysis](https://github.com/LSSTDESC/CLMM/blob/main/examples/mass_fitting/Example4_Fit_Halo_mass_to_HSC_data.ipynb), but missing some at the moment), to the `merged_cat_wl` catalog. There might be more cuts to implement to improve sample purity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aee903-ea0f-4006-8986-300b280eb473",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_cat_wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0054192f-75f8-4910-b40f-bf1095fc3c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_cat_wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa55d85a-fd19-4fe6-b878-0daaeea4a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute again magnitudes, but for the RS-free catalog\n",
    "mag_i = -2.50 * np.log10(merged_cat_wl['i_cModelFlux']) + 31.4\n",
    "mag_r = -2.50 * np.log10(merged_cat_wl['r_cModelFlux']) + 31.4\n",
    "\n",
    "# Filters to keep sources with good-quality measured shape in i band\n",
    "source_filt = np.isfinite(merged_cat_wl['i_hsmShapeRegauss_e1'])\n",
    "source_filt &= np.isfinite(merged_cat_wl['i_hsmShapeRegauss_e2'])\n",
    "source_filt &= np.sqrt(merged_cat_wl['i_hsmShapeRegauss_e1']**2 + merged_cat_wl['i_hsmShapeRegauss_e2']**2) < 4\n",
    "source_filt &= merged_cat_wl['i_hsmShapeRegauss_sigma']<= 0.4 \n",
    "source_filt &= merged_cat_wl['i_hsmShapeRegauss_flag'] == 0\n",
    "source_filt &= merged_cat_wl['i_blendedness'] < 0.42\n",
    "source_filt &= merged_cat_wl['i_iPSF_flag']==0\n",
    "\n",
    "# Resolution factor quality cut - according to Mandelbaum (2018) paper:\n",
    "# \"we use the resolution factor R2 which is defined using the trace of the moment matrix of the PSF TP and \n",
    "# of the observed (PSF-convolved) galaxy image TI as: R2 = 1- TP/TI\"\n",
    "# Best guess to translate that in terms of ComCam objectTable catalog output...\n",
    "\n",
    "res = 1 - (merged_cat_wl['i_ixxPSF']+ merged_cat_wl['i_iyyPSF']) / (merged_cat_wl['i_ixx']+ merged_cat_wl['i_iyy'])\n",
    "source_filt &= res >= 0.3\n",
    "\n",
    "# NB: Resolution needs to be double checked. As pointed out by Anthony, \n",
    "# the 'ext_shapeHSM_HsmShapeRegauss_resolution' column exists in \n",
    "# the deepCoadd_obj 'meas' table  but not in the objectTable table. Would need a match between the two to\n",
    "# pull the resolution directly from the meas table rather than recomputing it here (comparing the two \n",
    "# would be a good check of whether the formula below is the right one to use). To be done/investigated.\n",
    "\n",
    "source_filt &= mag_i <= 24.5\n",
    "#source_filt &= mag_i > 20. # to remove the brightest objects that are likely foreground objects\n",
    "\n",
    "print(f'Source sample size: {np.sum(source_filt)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b041b07-feb2-4f79-8c26-dd0ac50af6d0",
   "metadata": {},
   "source": [
    "### Final source sample CMD, (ra,dec) distribution, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afff352-325d-4937-95f4-e7b67f769444",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, \n",
    "                         figsize=(4,4))\n",
    "ax.scatter(mag_r[source_filt], mag_r[source_filt]-mag_i[source_filt], marker='.', s=0.3) # all galaxies  \n",
    "ax.set_ylim([-1,2])\n",
    "ax.set_xlim([18,27])\n",
    "ax.set_ylabel('r-i')\n",
    "ax.set_xlabel('r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25471a2c-3805-48e0-8424-d0e65c1cf649",
   "metadata": {},
   "source": [
    "## Applying Masks\n",
    "\n",
    "For examples, check out [this notebook](https://github.com/lsst-sitcom/comcam_clusters/blob/main/A360_masking_example.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a4c139-02d0-4a3e-9e04-5eb72ad7fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_hsp = hsp.HealSparseMap.read('/home/b/bclevine/A360/A360_full_mask_hsp_128_131072.parquet')\n",
    "\n",
    "# mask = ~mask_hsp['full_mask'].get_values_pos(shear_table_wl['ra'], shear_table_wl['dec'], lonlat=True)\n",
    "star_mask = ~mask_hsp['bo'].get_values_pos(merged_cat_wl['coord_ra'], merged_cat_wl['coord_dec'], lonlat=True) # bright objects\n",
    "dust_mask = ~mask_hsp['sfd'].get_values_pos(merged_cat_wl['coord_ra'], merged_cat_wl['coord_dec'], lonlat=True) # masks from SFD dust map\n",
    "hand_mask = ~mask_hsp['hand'].get_values_pos(merged_cat_wl['coord_ra'], merged_cat_wl['coord_dec'], lonlat=True)  # masks done by hand, e.g. galactic cirrus\n",
    "exp_mask = ~mask_hsp['exp'].get_values_pos(merged_cat_wl['coord_ra'], merged_cat_wl['coord_dec'], lonlat=True) # edge / num exp mask\n",
    "\n",
    "mask = star_mask & dust_mask & hand_mask & exp_mask\n",
    "\n",
    "print(\"Number of rows in before mask applied: \", len(merged_cat_wl))\n",
    "merged_cat_wl = merged_cat_wl[mask]\n",
    "print(\"Number of rows in ns after mask applied : \", len(merged_cat_wl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fcb2a0-fc81-4950-a1fa-d96e22ad468e",
   "metadata": {},
   "source": [
    "## Final Check and Useful Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9a61a-9fe0-415d-9f5d-a479d68b8769",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = merged_cat_wl['coord_ra'][source_filt]\n",
    "dec = merged_cat_wl['coord_dec'][source_filt]\n",
    "e1 = merged_cat_wl['i_hsmShapeRegauss_e1'][source_filt]\n",
    "e2 = merged_cat_wl['i_hsmShapeRegauss_e2'][source_filt]\n",
    "e_err = merged_cat_wl['i_hsmShapeRegauss_sigma'][source_filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9063095f-9f59-4af6-bd3e-90dd47f2959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ra, dec, marker='.', s=0.2)\n",
    "plt.scatter([ra_bcg], [dec_bcg], marker='+', s=100, color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b93fb66-2d1b-49e4-8a61-d67942ef6b2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T15:54:39.992227Z",
     "iopub.status.busy": "2025-02-27T15:54:39.991847Z",
     "iopub.status.idle": "2025-02-27T15:54:39.993946Z",
     "shell.execute_reply": "2025-02-27T15:54:39.993660Z",
     "shell.execute_reply.started": "2025-02-27T15:54:39.992214Z"
    }
   },
   "source": [
    "## Apply HSC shear calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c99a9-d60f-40c7-adbb-a2fdd0261f32",
   "metadata": {},
   "source": [
    "### Save source catalog `merged_cat_wl` as fits file to use as input for the HSC calibration script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee3b7a-16be-4ef1-be44-dd382ca44efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.table import Table, vstack\n",
    "import pandas as pd\n",
    "\n",
    "# Too many columns in the pandas dataframe. Remove some unecessary ones.\n",
    "import re\n",
    "# Define pattern (example: drop all columns starting with \"temp_\")\n",
    "pattern = r\"^g_|^z_\"  \n",
    "# Drop columns matching the pattern\n",
    "merged_cat_wl = merged_cat_wl.drop(columns=[col for col in merged_cat_wl.columns if re.match(pattern, col)])\n",
    "\n",
    "astropy_table = Table.from_pandas(merged_cat_wl[source_filt])\n",
    "astropy_table.write('source_sample.fits', format=\"fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7678b645-c6a5-4bff-845b-8c87811d6a92",
   "metadata": {},
   "source": [
    "Now that the source_sample.fits file exists, need to use the HSC calibration in the command line. The `get_snr, get_res, get_psf_ellip` functions in the `utilities.py` file from the HSC calibration repo first need to be updated to use the column names of DP1. Then run:\n",
    "```\n",
    "python gen_hsc_calibrations.py source_sample.fits source_sample_calib.fits\n",
    "```\n",
    "which will create the `source_sample_calib.fits` file that is read below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b42c91-e617-459a-9fd2-9bcd873abe1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T08:50:49.871749Z",
     "iopub.status.busy": "2025-03-11T08:50:49.871448Z",
     "iopub.status.idle": "2025-03-11T08:50:49.873940Z",
     "shell.execute_reply": "2025-03-11T08:50:49.873606Z",
     "shell.execute_reply.started": "2025-03-11T08:50:49.871734Z"
    }
   },
   "source": [
    "### Read in the calibration quantities and apply the calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8aeb9a-de58-4fca-88e0-dbf7486f3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.table import Table, vstack\n",
    "import pandas as pd\n",
    "\n",
    "with fits.open('source_sample_calib.fits') as hdul:\n",
    "    # Assuming data is in the first HDU (if not, change the index as needed)\n",
    "    data = hdul[1].data\n",
    "\n",
    "    # Convert the FITS data to an Astropy Table\n",
    "    table = Table(data)\n",
    "\n",
    "e_rms = table[\"ishape_hsm_regauss_derived_rms_e\"]\n",
    "m = table[\"ishape_hsm_regauss_derived_shear_bias_m\"]\n",
    "c1 = table[\"ishape_hsm_regauss_derived_shear_bias_c1\"]\n",
    "c2 = table[\"ishape_hsm_regauss_derived_shear_bias_c2\"]\n",
    "weight = table[\"ishape_hsm_regauss_derived_shape_weight\"]\n",
    "\n",
    "to_use = np.isfinite(weight)*np.isfinite(e_rms)*np.isfinite(m)*np.isfinite(c1)*np.isfinite(c2)\n",
    "\n",
    "e1_0 = e1[to_use]\n",
    "e2_0 = e2[to_use]\n",
    "e_rms = e_rms[to_use]\n",
    "c1 = c1[to_use]\n",
    "c2 = c2[to_use]\n",
    "m = m[to_use]\n",
    "weight = weight[to_use]\n",
    "\n",
    "print(f'Number of sources with calibration: {np.sum(to_use)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c3ff7-b4df-49ea-ba0b-f0adb93b564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Shenming's CLMM demo on using HSC data\n",
    "def apply_shear_calibration(e1_0, e2_0, e_rms, m, c1, c2, weight):\n",
    "    R = 1.0 - np.sum(weight * e_rms**2.0) / np.sum(weight)\n",
    "    m_mean = np.sum(weight * m) / np.sum(weight)\n",
    "    c1_mean = np.sum(weight * c1) / np.sum(weight)\n",
    "    c2_mean = np.sum(weight * c2) / np.sum(weight)\n",
    "    print(\"R, m_mean, c1_mean, c2_mean: \", R, m_mean, c1_mean, c2_mean)\n",
    "\n",
    "    g1 = (e1_0 / (2.0 * R) - c1) / (1.0 + m_mean)\n",
    "    g2 = (e2_0 / (2.0 * R) - c2) / (1.0 + m_mean)\n",
    "\n",
    "    return g1, g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713af3e-07ce-4a4c-b758-059625117444",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1, g2 = apply_shear_calibration(e1_0, e2_0, e_rms, m, c1, c2, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666f65e6-8be6-43af-b925-aa6fe7af5162",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(e1[to_use], bins=100, alpha=0.2, range=[-2, 2], label='e1');\n",
    "plt.hist(g1, bins=100, alpha=0.2,range=[-2, 2], label='g1 - calibrated');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f38364-786a-43a2-ae1c-2d21785ed55b",
   "metadata": {},
   "source": [
    "## Mass Aperture Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9894bd21-bfd7-497c-99ab-b8ec4f4011dd",
   "metadata": {},
   "source": [
    "Mass aperture statistics are one way of mapping the distribution of dark matter across a cluster, it's an integral statistic which convolves the observed shears with a filter optimized to match a given profile. For LoVoCCS, we normally use a 'Schirmer filter' (e.g. Schirmer+04, Hetterscheidt+05, Schirmer+06, McCleary+18). The full data reduction for LoVoCCS is hosted in a public repository, [lovoccs_pipe](https://github.com/astroenglert/lovoccs_pipe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b637bfb6-799b-4e15-8a08-02801eba2993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schirmer_filter(radius,aperture_size=8000,x_cut=0.15,a=6,b=150,c=47,d=50,*_):\n",
    "    '''\n",
    "    The Schirmer Filter, a filter which is optimized for detecting NFW-like structures in shear-fields.\n",
    "    \n",
    "    Args:\n",
    "        radius: Numpy array; an array of radii to evaluate the filter on\n",
    "        aperture_size: float-like; the 'schirmer-radius' of the filter\n",
    "        x_cut: float-like; specifies the filter-sloap and sets the characteristic-scale of the filter to x_cut*smoothing\n",
    "    \n",
    "    Returns:\n",
    "        Q; Numpy array; an array containing the filter evaluated at each radius\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    x = radius/aperture_size\n",
    "    Q = ( 1/( 1 + np.exp(a - b*x) + np.exp(-c + d*x)) )*( np.tanh(x/x_cut)/(x/x_cut) )\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924383f-07c0-4fad-9661-73ad4d41ec7a",
   "metadata": {},
   "source": [
    "For the time being, I'll write this to work on a flat-sky approximation since we're only dealing with a ~0.5deg cutout surrounding the cluster. This uses a direct estimator for the aperture mass statistic at each point and evaluates it on a series of \"grid-points\" specified by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f84e717-295a-42fc-8e2f-4f62d4082f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mass_map(x_grid,y_grid,x,y,g1,g2,weights,q_filter,filter_kwargs={}):\n",
    "    '''\n",
    "    This function computes the mass aperture-statistics at each point on a specified grid. Run quality-cuts, NaN filtering, etc. before this step!\n",
    "    \n",
    "    Args:\n",
    "        x: Numpy array; an array of x-coordinates for each object\n",
    "        y: Numpy array; an array of y-coordinates for each object\n",
    "        x_grid: Numpy array; an NxM array of x-coordinates to sample the aperture-mass on\n",
    "        y_grid: Numpy array; an NxM array of y-coordinates to sample the aperture-mass on\n",
    "        g1; Numpy array; the shear g1 for each object\n",
    "        g2; Numpy array; the shear g2 for each object\n",
    "        weights: Numpy array; the weight for each object's shear\n",
    "        q_filter; function; the filter-function used to compute Map\n",
    "        kwargs; dict; kwargs passed to w_filter\n",
    "    \n",
    "    Returns:\n",
    "        Map_E: Numpy array; an NxM array containing the E-mode aperture mass evaluated at each grid-point\n",
    "        Map_B: Numpy array; an NxM array containing the B-mode aperture mass evaluated at each grid-point\n",
    "        Map_V: Numpy array; an NxM array containing the variance in the aperture mass evaluated at each grid-point\n",
    "\n",
    "    '''\n",
    "\n",
    "    y_shape = len(y_grid[:,0])\n",
    "    x_shape = len(x_grid[0,:])\n",
    "    \n",
    "    Map_E = np.zeros((y_shape,x_shape))\n",
    "    Map_B = np.zeros((y_shape,x_shape))\n",
    "    Map_V = np.zeros((y_shape,x_shape))\n",
    "    \n",
    "    if 'aperture_size' not in filter_kwargs:\n",
    "        filter_area = np.pi * (8000)**2\n",
    "    else:\n",
    "        filter_area = np.pi * filter_kwargs['aperture_size']**2\n",
    "    \n",
    "    # an extra catch for an objects assigned NaN g1/g2 just in case\n",
    "    nan_catch = np.isfinite(g1) & np.isfinite(g2)\n",
    "    x = x[nan_catch]\n",
    "    y = y[nan_catch]\n",
    "    g1 = g1[nan_catch]\n",
    "    g2 = g2[nan_catch]\n",
    "    weights = weights[nan_catch]\n",
    "    \n",
    "    for i in range(y_shape):\n",
    "        for j in range(x_shape):\n",
    "            delta_x = x_grid[j,i] - x\n",
    "            delta_y = y_grid[j,i] - y\n",
    "            radius = np.sqrt(delta_x**2 + delta_y**2)\n",
    "            theta = np.arctan2(delta_y,delta_x)\n",
    "            g_T = -g1*np.cos(2*theta) - g2*np.sin(2*theta)\n",
    "            g_X =  g1*np.sin(2*theta) - g2*np.cos(2*theta)\n",
    "            g_mag = g1**2 + g2**2\n",
    "            \n",
    "            filter_values = q_filter(radius,**filter_kwargs)\n",
    "\n",
    "            weight_sum = np.sum(weights)\n",
    "            \n",
    "            Map_E[i,j] = np.sum(filter_values*g_T*weights)*filter_area/weight_sum\n",
    "            Map_B[i,j] = np.sum(filter_values*g_X*weights)*filter_area/weight_sum\n",
    "            Map_V[i,j] = np.sum( (filter_values**2)*g_mag*(weights**2) )*(filter_area**2)/(2*(weight_sum**2))\n",
    "            \n",
    "    return Map_E, Map_B, Map_V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6a3571-8a1b-4685-bb50-7798f1a5ac84",
   "metadata": {},
   "source": [
    "Let's define a grid of x and y coordinates from the catalog of selected galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415a52a-e0e0-4237-a6a7-9a4fc63c0d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, setup a coordinates for a flat-sky in x and y\n",
    "# create a WCS and use the corresponding method to transform sky to px coords\n",
    "\n",
    "# load wcs from astropy\n",
    "from astropy.wcs import WCS\n",
    "from astropy.wcs.utils import skycoord_to_pixel\n",
    "\n",
    "# also load skycoord for the conversion\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "# build wcs centered on BCG\n",
    "flat_wcs = WCS(naxis=2)\n",
    "crval_sky = [ra_bcg*u.deg,dec_bcg*u.deg]\n",
    "flat_wcs.wcs.crval = [ra_bcg,dec_bcg]\n",
    "flat_wcs.wcs.crpix = [0,0] # assign 0,0 to the center, shouldn't matter\n",
    "flat_wcs.wcs.cdelt = [-0.2/3600,0.2/3600] # match angular resolution of LSST, 0.2\"\n",
    "flat_wcs.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\"]\n",
    "flat_wcs.wcs.radesys = 'ICRS'\n",
    "flat_wcs.wcs.equinox = 2000\n",
    "flat_wcs.wcs.cd = [[-0.2/3600,0],[0,0.2/3600]]\n",
    "\n",
    "# compute coords in the flat-sky\n",
    "# coords = SkyCoord(ra=merged_cat_wl['coord_ra'][source_filt][to_use],dec=merged_cat_wl['coord_dec'][source_filt][to_use],unit='degree')\n",
    "coords = SkyCoord(ra=ra,dec=dec,unit='degree')\n",
    "x,y = skycoord_to_pixel(coords,wcs=flat_wcs)\n",
    "\n",
    "# scale these up to units of degrees to match mass_map spacing and make writing the aperture easier\n",
    "x = x * 0.2/3600\n",
    "y = y * 0.2/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5fbd91-499f-405f-9462-bdca1ddb9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now I'll weight everything uniformly\n",
    "weights = weight #np.ones(len(x))\n",
    "\n",
    "# Define an NxN grid centered on the cluster\n",
    "# Spans 1-deg centered at the BCG\n",
    "# scale so that its in pixel coordinates for computing\n",
    "N = 121\n",
    "\n",
    "mid_x = 0\n",
    "mid_y = 0\n",
    "x_grid_samples = np.linspace(mid_x-0.5,mid_x+0.5,N)\n",
    "y_grid_samples = np.linspace(mid_y-0.5,mid_y+0.5,N)\n",
    "y_grid,x_grid = np.meshgrid(y_grid_samples,x_grid_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b860c-5d75-4cfb-96f9-261e175773a7",
   "metadata": {},
   "source": [
    "Define a WCS for this grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be5387-35c2-464d-afdd-6786f5493a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load wcs from astropy\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "# build wcs centered on BCG\n",
    "Map_wcs = WCS(naxis=2)\n",
    "crval_sky = [ra_bcg*u.deg,dec_bcg*u.deg]\n",
    "Map_wcs.wcs.crval = [ra_bcg,dec_bcg]\n",
    "Map_wcs.wcs.crpix = [N//2, N//2]\n",
    "Map_wcs.wcs.cdelt = [-1/N,1/N]\n",
    "Map_wcs.wcs.ctype = [\"RA---TAN\", \"DEC--TAN\"]\n",
    "Map_wcs.wcs.radesys = 'ICRS'\n",
    "Map_wcs.wcs.equinox = 2000\n",
    "Map_wcs.wcs.cd = [[-1/N,0],[0,1/N]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509af9eb-777b-4958-99f1-bebc9e1e7716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes a minute to run\n",
    "e_ap,b_ap,v_ap = compute_mass_map(x_grid,y_grid,x,y,g1,g2,weights,schirmer_filter,filter_kwargs={'aperture_size':0.4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49fcba0-ea84-40ab-82c1-405bfc80cd58",
   "metadata": {},
   "source": [
    "One last thing is useful here... technically a signal $ S > S_0 $ doesn't correspond to an $S_0$-sigma detection (the errors within a given pixel are not Poisson and potentially non-Gaussian). A simple way of getting the statistical confidence is by shuffling the galaxy shapes and rotating the shears to create new realizations of the shot-noise with the lensing signal dissolved. This neglects the introduction of peaks due to LSS, but for studying a single cluster this can be neglected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f382f8df-3581-4fcd-aed5-e513760a31db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, I need to get confidence intervals for the peak pixel, I can do this pretty easily\n",
    "# FIRST, let's get the location of the peak-pixel (in degrees, truncating the noise-peaks near the edge of the map)\n",
    "peak_px = np.unravel_index(np.argmax((e_ap/np.sqrt(v_ap))[int(N/2) - 30:int(N/2) + 30,int(N/2) - 30:int(N/2) + 30]),np.shape(e_ap))\n",
    "\n",
    "from astropy.wcs.utils import pixel_to_skycoord\n",
    "x_peak = peak_px[1]/N - 0.5\n",
    "y_peak = peak_px[0]/N - 0.5\n",
    "\n",
    "# mimic N-realizations of shot-noise\n",
    "realizations = 5000\n",
    "\n",
    "filter_these = np.isfinite(g1) & np.isfinite(g2)\n",
    "x_temp = x[filter_these]\n",
    "y_temp = y[filter_these]\n",
    "g1_temp = g1[filter_these]\n",
    "g2_temp = g2[filter_these]\n",
    "weights_temp = weights[filter_these]\n",
    "\n",
    "peak_S = []\n",
    "for i in range(realizations):\n",
    "\n",
    "    # shuffle phase for each realization to dissolve the signal\n",
    "    random_phase = np.random.rand(len(x))*2*np.pi\n",
    "    g1_rot = - np.array(g1_temp) * np.cos(2*random_phase) - np.array(g2_temp) * np.sin(2*random_phase)\n",
    "    g2_rot = np.array(g1_temp) * np.sin(2*random_phase) - np.array(g2_temp) * np.sin(2*random_phase)\n",
    "\n",
    "    # and uniformly sample a circle covering the cluster, 0.5deg ~ 9000px radius\n",
    "    random_polar = np.random.rand(len(x_temp))*2*np.pi\n",
    "    random_radius = np.random.rand(len(x_temp))*9000*(0.2/3600)\n",
    "    random_x = np.cos(random_polar)*random_radius\n",
    "    random_y = np.sin(random_polar)*random_radius\n",
    "\n",
    "    # neglecting covariances/correlations, this should mimic the shape noise\n",
    "    # collect S-statistics from these noise realizations at the peak pixel\n",
    "\n",
    "    # for single-pixel S-statistic\n",
    "    temp_e,temp_b,temp_v = compute_mass_map(np.array([[x_peak]]),np.array([[y_peak]]),random_x,random_y,g1_rot,g2_rot,weights_temp,schirmer_filter,filter_kwargs={'aperture_size':0.4})\n",
    "    \n",
    "    # generate full \"noise maps\"\n",
    "    peak_S.append(temp_e/np.sqrt(temp_v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2e8306-b654-4c46-a5b3-fddf9a3e41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "points=np.linspace(-10,10,10000)\n",
    "mean = np.mean(peak_S)\n",
    "std = np.std(peak_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a7012e-336e-4491-8893-05671fc72bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_peak = (e_ap/np.sqrt(v_ap)).max()\n",
    "true_peak_index = np.argmin(np.abs(true_peak - points))\n",
    "Z = (np.abs(e_ap/np.sqrt(v_ap)).max() - mean)/std\n",
    "\n",
    "true_peak_b = (b_ap/np.sqrt(v_ap))[int(N/2) - 30:int(N/2) + 30,int(N/2) - 30:int(N/2) + 30].max()\n",
    "Z_b = (true_peak_b - mean)/std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337b020-5cef-4b7a-ad96-18cba064acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fortunately, the distribution of values here appears gaussian, so we can estimate the statistical confidence easily\n",
    "plt.hist(np.array(peak_S).flatten(),density=True,bins=20,histtype='step',label='Simulated Noise');\n",
    "\n",
    "pdf_per_px = 1/(std*np.sqrt(2*np.pi)) * np.exp( -0.5 * ( ( points - mean )/std )**2 )\n",
    "plt.plot(points,pdf_per_px,label='Gaussian Model')\n",
    "plt.xlim((-6.2,6.2))\n",
    "plt.ylim((0,0.46))\n",
    "\n",
    "plt.vlines(x=true_peak_b,ymin=0,ymax=0.5,linestyle='--',color='C2',label='Radial Mode Peak')\n",
    "plt.vlines(x=true_peak,ymin=0,ymax=0.5,linestyle='--',color='C3',label='Tangent Mode Peak')\n",
    "plt.xlabel('$ S_0 $')\n",
    "plt.ylabel('$ p(S_0) $')\n",
    "plt.title('S-Statistic Noise')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.savefig('signal_statistic_noise.pdf',dpi=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b5319-454b-4287-bdf6-3a7291508ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Peak amplitude\", (e_ap/np.sqrt(v_ap)).max())\n",
    "print(\"Z-score (E-mode peak)\", Z)\n",
    "print(\"Z_b-score (B-mode peak)\", Z_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b747d5b5-0f59-447a-b5a7-0bd64e815577",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2,subplot_kw=dict(projection=Map_wcs),figsize=(10,6))\n",
    "\n",
    "txt_fmt = lambda x : f'$ {int(x):0} \\\\sigma $'\n",
    "ax = axs[0]\n",
    "ax.set_title('Tangential Mode')\n",
    "MapE = ax.imshow(e_ap/np.sqrt(v_ap),origin='lower',vmax=6,vmin=-2)\n",
    "\n",
    "lon = ax.coords[0]\n",
    "lat = ax.coords[1]\n",
    "ax.set_xlim((20,100))\n",
    "ax.set_ylim((20,100))\n",
    "\n",
    "lon.set_major_formatter('d.d')\n",
    "lat.set_major_formatter('d.d')\n",
    "lon.set_axislabel('RA')\n",
    "lat.set_axislabel('DEC')\n",
    "\n",
    "ax = axs[1]\n",
    "ax.set_title('Radial Mode')\n",
    "MapB = ax.imshow(b_ap/np.sqrt(v_ap),origin='lower',vmax=6,vmin=-2)\n",
    "\n",
    "lon = ax.coords[0]\n",
    "lat = ax.coords[1]\n",
    "ax.set_xlim((20,100))\n",
    "ax.set_ylim((20,100))\n",
    "\n",
    "\n",
    "lon.set_major_formatter('d.d')\n",
    "lat.set_major_formatter('d.d')\n",
    "lon.set_axislabel('')\n",
    "lat.set_axislabel('')\n",
    "lon.set_axislabel('RA')\n",
    "lat.set_axislabel('DEC')\n",
    "plt.tight_layout()\n",
    "\n",
    "cbar = fig.colorbar(MapE, ax=axs,fraction=0.025)\n",
    "fig.savefig('ACO360_mass_map.pdf',dpi=480,bbox_inches='tight')\n",
    "# woohoo, we have a signal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf140d4-a6ab-447e-8892-b4be1b7d80e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this as a .fits file so we don't have to constantly recompute it\n",
    "header = Map_wcs.to_header()\n",
    "\n",
    "Map_E_hdu = fits.PrimaryHDU(data=e_ap,header=header)\n",
    "Map_B_hdu = fits.ImageHDU(data=b_ap,name='M_B')\n",
    "Map_V_hdu = fits.ImageHDU(data=v_ap,name='M_V')\n",
    "\n",
    "# create the hdul and write it to disk\n",
    "hdul = fits.HDUList([Map_E_hdu,Map_B_hdu,Map_V_hdu])\n",
    "hdul.writeto(\"A360_mass_map.fits\",overwrite=True)\n",
    "\n",
    "# if you need to access this, it can be found at /home/e/englert/A360_mass_map.fits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
